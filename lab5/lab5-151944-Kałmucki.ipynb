{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Playing games!"]},{"cell_type":"markdown","metadata":{},"source":["In this assignment your task is to make computer play games. Of course, we limit ourselves to a very limited subset of games: two players, zero sum, perfect information, deterministic games. These properties may require some explanation:\n","\n","* *Two players* is pretty straightforward: there are exactly two players. Any less is a puzzle (see previous classes), any more is interesting (but out of scope).\n","* *Zero sum* means that a win of one player is necessarly a loss of the other player. For example, if one player wins the game having 100 points, the other player must have exactly -100 points.\n","* *Perfect information* means that there are no hidden variables in the game, like some cards kept in secret by players. Both players can see exactly the same thing.\n","* *Deterministic* means that there is no randomness in the game, no dices, no decks of cards, etc.\n","\n","Each and every of these assumptions can be relaxed, yielding a more complex variant of the problem of playing games."]},{"cell_type":"markdown","metadata":{},"source":["## Game\n","\n","We begin by defining a general class `Game`, equipped with 7 functions:\n","\n","* `initial_state` returns a representation of an intial state of the game, e.g., an empty board and an information which player plays first. State is opaque to search algorithms, similarly as in the classes on Agents and A*.\n","* `player` return the id of a player to make a move in the given `state`. Here we consistently use number 1 to represent the first player and 2 to represent the second player, but in general any two distict identifiers would suffice.\n","* `actions` returns a list of valid moves in the given state. This corresponds to the list of available actions in previous classes.\n","* `result` returns a new state after performing the given `action` in the given `state`. This is the transition model underpinning the game.\n","* `is_terminal` returns `True` if the given `state` is a terminal node in the search tree, i.e., either one of the players won or it is a draw. This is a leaf in a search tree and no further actions can be executed.\n","* `utility` can be called only for a terminal `state` and returns a numeric representation of how good this state is for the given `player`. Because we are considering zero-sum games it is always true that `utility(state, 1) = -utility(state, 2)`\n","* `print_state` is a helper function to pretty-print the given `state` to the standard output. As the representation is opaque and possibly hard to read for a human, this little function will make our lives much easier further down the line."]},{"cell_type":"code","execution_count":112,"metadata":{},"outputs":[],"source":["class Game:\n","    @property\n","    def initial_state(self):\n","        ...\n","        return state\n","    \n","    def player(self, state):\n","        ...\n","        return playerno\n","        \n","    def actions(self, state):\n","        ...\n","        return actions\n","        \n","    def result(self, state, action):\n","        ...\n","        return new_state\n","        \n","    def is_terminal(self, state):\n","        ...\n","        return boolean\n","        \n","    def utility(self, state, player):\n","        ...        \n","        return number\n","        \n","    def print_state(self, state):\n","        ...        "]},{"cell_type":"markdown","metadata":{},"source":["For convenience we define a simple function `opponent` that, given a player id, returns the id of the other player."]},{"cell_type":"code","execution_count":113,"metadata":{},"outputs":[],"source":["def opponent(player):    \n","    assert player in {1, 2}\n","    if player == 1:\n","        return 2\n","    else:\n","        return 1"]},{"cell_type":"markdown","metadata":{},"source":["## Tic-Tac-Toe\n","\n","The first game we'll consider is *Tic-Tac-Toe* (*noughts and crosses*) in its bare minimum. For completeness, let me quote [Wikipedia](https://en.wikipedia.org/w/index.php?title=Tic-tac-toe&oldid=986503204) on rules: \n","\n","> Tic-tac-toe (American English), noughts and crosses (Commonwealth English), or Xs and Os, is a paper-and-pencil game for two players, X and O, who take turns marking the spaces in a 3×3 grid. The player who succeeds in placing three of their marks in a horizontal, vertical, or diagonal row is the winner. It is a solved game with a forced draw assuming best play from both players."]},{"cell_type":"code","execution_count":114,"metadata":{},"outputs":[],"source":["class TicTacToe(Game):    \n","    @property\n","    def initial_state(self):\n","        return (1, (0,)*9)\n","    \n","    def player(self, state):\n","        return state[0]\n","        \n","    def actions(self, state):\n","        return [i for i, v in enumerate(state[1]) if v == 0]\n","        \n","    def result(self, state, action):\n","        board = state[1]\n","        assert board[action] == 0\n","        assert state[0] in {1, 2}\n","        board = board[:action] + (state[0],) + board[action+1:]\n","        next_player = opponent(state[0])        \n","        return (next_player, board)\n","        \n","    def _has_line(self, state, player):\n","        board = state[1]\n","        for i in [0, 3, 6]:\n","            if board[i] == board[i+1] == board[i+2] == player:\n","                return True\n","        for i in [0, 1, 2]:\n","            if board[i] == board[i+3] == board[i+6] == player:\n","                return True\n","        if board[0] == board[3+1] == board[2*3+2] == player:\n","            return True\n","        if board[2] == board[3+1] == board[2*3] == player:\n","            return True\n","        return False\n","        \n","    def is_terminal(self, state):\n","        if all([v != 0 for v in state[1]]):\n","            return True\n","        return self._has_line(state, 1) or self._has_line(state, 2)\n","    \n","    def utility(self, state, player):\n","        assert player in {1, 2}\n","        mine = self._has_line(state, player)\n","        opponents = self._has_line(state, opponent(player))\n","        if mine and not opponents:\n","            return 1\n","        if not mine and opponents:\n","            return -1\n","        return 0    \n","    \n","    def print_state(self, state):\n","        print(\"Player making move\", \" OX\"[state[0]])\n","        board = [\"_OX\"[v] for v in state[1]]\n","        print(*board[0:3])\n","        print(*board[3:6])\n","        print(*board[6:9])"]},{"cell_type":"markdown","metadata":{},"source":["The actions are represented by the number of field where to put a mark, using the following map:\n","```\n","0|1|2\n","-----\n","3|4|5\n","-----\n","6|7|8\n","```\n","\n","The cell below executes a sequence of actions that leads to a draw."]},{"cell_type":"code","execution_count":115,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move O\n","_ _ _\n","_ _ _\n","_ _ _\n","Player making move X\n","_ _ _\n","_ O _\n","_ _ _\n","Player making move O\n","X _ _\n","_ O _\n","_ _ _\n","Player making move X\n","X _ _\n","_ O _\n","O _ _\n","Player making move O\n","X _ X\n","_ O _\n","O _ _\n","Player making move X\n","X O X\n","_ O _\n","O _ _\n","Player making move O\n","X O X\n","_ O _\n","O X _\n","Player making move X\n","X O X\n","_ O O\n","O X _\n","Player making move O\n","X O X\n","X O O\n","O X _\n","Player making move X\n","X O X\n","X O O\n","O X O\n","Reached terminal state? True\n","Utility for the 1st player 0\n","Utility for the 2nd player 0\n"]}],"source":["game = TicTacToe()\n","state = game.initial_state\n","game.print_state(state)\n","\n","for action in [4,0,6,2,1,7,5,3,8]:\n","    assert action in game.actions(state)\n","    assert not game.is_terminal(state)\n","    state = game.result(state, action)\n","    game.print_state(state)\n","    \n","print(\"Reached terminal state?\", game.is_terminal(state))\n","print(\"Utility for the 1st player\", game.utility(state, 1))\n","print(\"Utility for the 2nd player\", game.utility(state, 2))"]},{"cell_type":"markdown","metadata":{},"source":["Below, 2 plays suboptimally and loses."]},{"cell_type":"code","execution_count":116,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move O\n","_ _ _\n","_ _ _\n","_ _ _\n","Player making move X\n","_ _ _\n","_ O _\n","_ _ _\n","Player making move O\n","X _ _\n","_ O _\n","_ _ _\n","Player making move X\n","X _ _\n","_ O _\n","O _ _\n","Player making move O\n","X _ X\n","_ O _\n","O _ _\n","Player making move X\n","X O X\n","_ O _\n","O _ _\n","Player making move O\n","X O X\n","_ O _\n","O _ X\n","Player making move X\n","X O X\n","_ O _\n","O O X\n","Reached terminal state? True\n","Utility for the 1st player 1\n","Utility for the 2nd player -1\n"]}],"source":["game = TicTacToe()\n","state = game.initial_state\n","game.print_state(state)\n","\n","for action in [4,0,6,2,1,8,7]:\n","    assert action in game.actions(state)\n","    assert not game.is_terminal(state)\n","    state = game.result(state, action)\n","    game.print_state(state)\n","    \n","print(\"Reached terminal state?\", game.is_terminal(state))\n","print(\"Utility for the 1st player\", game.utility(state, 1))\n","print(\"Utility for the 2nd player\", game.utility(state, 2))"]},{"cell_type":"markdown","metadata":{},"source":["Finally, in the cell below 1 plays suboptimally and loses."]},{"cell_type":"code","execution_count":117,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move O\n","_ _ _\n","_ _ _\n","_ _ _\n","Player making move X\n","_ _ O\n","_ _ _\n","_ _ _\n","Player making move O\n","_ _ O\n","_ X _\n","_ _ _\n","Player making move X\n","_ _ O\n","_ X _\n","O _ _\n","Player making move O\n","X _ O\n","_ X _\n","O _ _\n","Player making move X\n","X _ O\n","_ X _\n","O O _\n","Player making move O\n","X _ O\n","_ X _\n","O O X\n","Reached terminal state? True\n","Utility for the 1st player -1\n","Utility for the 2nd player 1\n"]}],"source":["game = TicTacToe()\n","state = game.initial_state\n","game.print_state(state)\n","\n","for action in [2,4,6,0,7,8]:\n","    assert action in game.actions(state)\n","    assert not game.is_terminal(state)\n","    state = game.result(state, action)\n","    game.print_state(state)\n","    \n","print(\"Reached terminal state?\", game.is_terminal(state))\n","print(\"Utility for the 1st player\", game.utility(state, 1))\n","print(\"Utility for the 2nd player\", game.utility(state, 2))"]},{"cell_type":"markdown","metadata":{},"source":["## A judge and a dummy"]},{"cell_type":"markdown","metadata":{},"source":["Lets define a common interface for a player: it is a callable (e.g., a function) receiving two arguments: \n","\n","1. The definition of a game as an object of the class `Game`\n","2. A current state in which a move is to be made.\n","\n","The following function `dummy` follows this interface. It represents a player that always makes the first available move."]},{"cell_type":"code","execution_count":118,"metadata":{},"outputs":[],"source":["def dummy(game, state):\n","    return game.actions(state)[0]"]},{"cell_type":"markdown","metadata":{},"source":["To test players it is convenient to construct a general judge with three parameters:\n","\n","* `game` A definition of a game of type `Game`.\n","* `player1` A callable following the interface described above representing the first player.\n","* `player2` A callable following the interface described above representing the second player."]},{"cell_type":"code","execution_count":119,"metadata":{},"outputs":[],"source":["def judge(game: Game, player1, player2):    \n","    state = game.initial_state\n","\n","    while not game.is_terminal(state):\n","        if game.player(state) == 1:\n","            action = player1(game, state)\n","        else:\n","            action = player2(game, state)        \n","        game.print_state(state)\n","        print(\"Action:\", action)\n","        print()\n","        state = game.result(state, action)\n","\n","    game.print_state(state)\n","    print(\"Reached terminal state?\", game.is_terminal(state))\n","    u1 = game.utility(state, 1)\n","    u2 = game.utility(state, 2)\n","    print(\"Utility for the 1st player\", u1)\n","    print(\"Utility for the 2nd player\", u2)\n","    if u1 > u2:\n","        print(\"Winner: 1st player\")\n","    elif u1 < u2:\n","        print(\"Winner: 2nd player\")\n","    else:\n","        print(\"Draw\")"]},{"cell_type":"markdown","metadata":{},"source":["Lets see how well two dummies compete against each other in the game of Tic-Tac-Toe."]},{"cell_type":"code","execution_count":120,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move O\n","_ _ _\n","_ _ _\n","_ _ _\n","Action: 0\n","\n","Player making move X\n","O _ _\n","_ _ _\n","_ _ _\n","Action: 1\n","\n","Player making move O\n","O X _\n","_ _ _\n","_ _ _\n","Action: 2\n","\n","Player making move X\n","O X O\n","_ _ _\n","_ _ _\n","Action: 3\n","\n","Player making move O\n","O X O\n","X _ _\n","_ _ _\n","Action: 4\n","\n","Player making move X\n","O X O\n","X O _\n","_ _ _\n","Action: 5\n","\n","Player making move O\n","O X O\n","X O X\n","_ _ _\n","Action: 6\n","\n","Player making move X\n","O X O\n","X O X\n","O _ _\n","Reached terminal state? True\n","Utility for the 1st player 1\n","Utility for the 2nd player -1\n","Winner: 1st player\n"]}],"source":["judge(TicTacToe(), dummy, dummy)"]},{"cell_type":"markdown","metadata":{},"source":["## Task 1: Minimax algorithm\n","\n","Complete the following cell with an implementation of the mini-max algorithm. \n","The function should follow the interface for a player described above and return the best move to be made in the given `state` under the rules defined by the `game`."]},{"cell_type":"code","execution_count":121,"metadata":{},"outputs":[],"source":["#(⬇️) minimax using logic from lectures\n","def max_value(game: Game, state, player):\n","    if game.is_terminal(state):\n","        return game.utility(state,player), None\n","    v = float('-inf')\n","    for a in game.actions(state):\n","        v2, a2 = min_value(game, game.result(state,a), player)\n","        if v2 > v:\n","            v,move = v2, a\n","    return v, move\n","    \n","\n","def min_value(game: Game, state, player):\n","    if game.is_terminal(state):\n","        return game.utility(state,player), None\n","    v = float('inf')\n","    for a in game.actions(state):\n","        v2, a2 = max_value(game, game.result(state,a), player)\n","        if v2 < v:\n","            v, move = v2, a\n","    return v, move\n","\n","def minimax(game: Game, state):\n","    player = game.player(state)\n","    value, move = max_value(game, state,player)\n","    return move\n","    "]},{"cell_type":"markdown","metadata":{},"source":["Lets test your implementation against dummy and against itself. It should always win with dummy (dummy is deterministic and suboptimal) and it should draw with itself (Tic-Tac-Toe is a solved game and draw is the best outcome for optimal players).\n","We prefix the calls to `judge` with `%time` to measure time spent in the call. This will be useful to compare the performance of minimax with alpha-beta."]},{"cell_type":"code","execution_count":122,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move O\n","_ _ _\n","_ _ _\n","_ _ _\n","Action: 0\n","\n","Player making move X\n","O _ _\n","_ _ _\n","_ _ _\n","Action: 1\n","\n","Player making move O\n","O X _\n","_ _ _\n","_ _ _\n","Action: 3\n","\n","Player making move X\n","O X _\n","O _ _\n","_ _ _\n","Action: 2\n","\n","Player making move O\n","O X X\n","O _ _\n","_ _ _\n","Action: 4\n","\n","Player making move X\n","O X X\n","O O _\n","_ _ _\n","Action: 5\n","\n","Player making move O\n","O X X\n","O O X\n","_ _ _\n","Action: 6\n","\n","Player making move X\n","O X X\n","O O X\n","O _ _\n","Reached terminal state? True\n","Utility for the 1st player 1\n","Utility for the 2nd player -1\n","Winner: 1st player\n","Wall time: 1.86 s\n"]}],"source":["%time judge(TicTacToe(), minimax, dummy)"]},{"cell_type":"code","execution_count":123,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move O\n","_ _ _\n","_ _ _\n","_ _ _\n","Action: 0\n","\n","Player making move X\n","O _ _\n","_ _ _\n","_ _ _\n","Action: 4\n","\n","Player making move O\n","O _ _\n","_ X _\n","_ _ _\n","Action: 1\n","\n","Player making move X\n","O O _\n","_ X _\n","_ _ _\n","Action: 2\n","\n","Player making move O\n","O O X\n","_ X _\n","_ _ _\n","Action: 3\n","\n","Player making move X\n","O O X\n","O X _\n","_ _ _\n","Action: 6\n","\n","Player making move O\n","O O X\n","O X _\n","X _ _\n","Reached terminal state? True\n","Utility for the 1st player -1\n","Utility for the 2nd player 1\n","Winner: 2nd player\n","Wall time: 228 ms\n"]}],"source":["%time judge(TicTacToe(), dummy, minimax)"]},{"cell_type":"code","execution_count":124,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move O\n","_ _ _\n","_ _ _\n","_ _ _\n","Action: 0\n","\n","Player making move X\n","O _ _\n","_ _ _\n","_ _ _\n","Action: 4\n","\n","Player making move O\n","O _ _\n","_ X _\n","_ _ _\n","Action: 1\n","\n","Player making move X\n","O O _\n","_ X _\n","_ _ _\n","Action: 2\n","\n","Player making move O\n","O O X\n","_ X _\n","_ _ _\n","Action: 6\n","\n","Player making move X\n","O O X\n","_ X _\n","O _ _\n","Action: 3\n","\n","Player making move O\n","O O X\n","X X _\n","O _ _\n","Action: 5\n","\n","Player making move X\n","O O X\n","X X O\n","O _ _\n","Action: 7\n","\n","Player making move O\n","O O X\n","X X O\n","O X _\n","Action: 8\n","\n","Player making move X\n","O O X\n","X X O\n","O X O\n","Reached terminal state? True\n","Utility for the 1st player 0\n","Utility for the 2nd player 0\n","Draw\n","Wall time: 2.07 s\n"]}],"source":["%time judge(TicTacToe(), minimax, minimax)"]},{"cell_type":"markdown","metadata":{},"source":["## Task 2: Alpha-beta\n","\n","Mini-max is an optimal solution, but not the most efficient. Complete the following cell of code implementing the alpha-beta algorithm.\n","The function should follow the interface for a player described above and return the best move to be made in the given `state` under the rules defined by the `game`."]},{"cell_type":"code","execution_count":125,"metadata":{},"outputs":[],"source":["#(⬇️) alpha-beta using logic from lectures\n","def max_value(game: Game, state, player, A, B):\n","    if game.is_terminal(state):\n","        return game.utility(state,player), None\n","    v = float('-inf')\n","    for a in game.actions(state):\n","        v2, a2 = min_value(game, game.result(state,a), player, A, B)\n","        if v2 > v:\n","            v, move = v2, a\n","            A = max(A,v)\n","        if v >= B:\n","            return v, move\n","    return v, move\n","    \n","\n","def min_value(game: Game, state, player, A, B):\n","    if game.is_terminal(state):\n","        return game.utility(state,player), None\n","    v = float('inf')\n","    for a in game.actions(state):\n","        v2, a2 = max_value(game, game.result(state,a), player, A, B)\n","        if v2 < v:\n","            v, move = v2, a\n","            B  = min(B,v)\n","        if v <= A:\n","            return v, move\n","    return v, move\n","    \n","\n","def alphabeta(game, state):\n","    player = game.player(state)\n","    value, move = max_value(game, state, player, float('-inf'), float('inf'))\n","    return move"]},{"cell_type":"markdown","metadata":{},"source":["Again, lets test your implementation against dummy and against itself. It should behave in exactly the same way as minimax, but be faster."]},{"cell_type":"code","execution_count":126,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move O\n","_ _ _\n","_ _ _\n","_ _ _\n","Action: 0\n","\n","Player making move X\n","O _ _\n","_ _ _\n","_ _ _\n","Action: 1\n","\n","Player making move O\n","O X _\n","_ _ _\n","_ _ _\n","Action: 3\n","\n","Player making move X\n","O X _\n","O _ _\n","_ _ _\n","Action: 2\n","\n","Player making move O\n","O X X\n","O _ _\n","_ _ _\n","Action: 4\n","\n","Player making move X\n","O X X\n","O O _\n","_ _ _\n","Action: 5\n","\n","Player making move O\n","O X X\n","O O X\n","_ _ _\n","Action: 6\n","\n","Player making move X\n","O X X\n","O O X\n","O _ _\n","Reached terminal state? True\n","Utility for the 1st player 1\n","Utility for the 2nd player -1\n","Winner: 1st player\n","Wall time: 68.3 ms\n"]}],"source":["%time judge(TicTacToe(), alphabeta, dummy)"]},{"cell_type":"code","execution_count":127,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move O\n","_ _ _\n","_ _ _\n","_ _ _\n","Action: 0\n","\n","Player making move X\n","O _ _\n","_ _ _\n","_ _ _\n","Action: 4\n","\n","Player making move O\n","O _ _\n","_ X _\n","_ _ _\n","Action: 1\n","\n","Player making move X\n","O O _\n","_ X _\n","_ _ _\n","Action: 2\n","\n","Player making move O\n","O O X\n","_ X _\n","_ _ _\n","Action: 3\n","\n","Player making move X\n","O O X\n","O X _\n","_ _ _\n","Action: 6\n","\n","Player making move O\n","O O X\n","O X _\n","X _ _\n","Reached terminal state? True\n","Utility for the 1st player -1\n","Utility for the 2nd player 1\n","Winner: 2nd player\n","Wall time: 14 ms\n"]}],"source":["%time judge(TicTacToe(), dummy, alphabeta)"]},{"cell_type":"code","execution_count":128,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move O\n","_ _ _\n","_ _ _\n","_ _ _\n","Action: 0\n","\n","Player making move X\n","O _ _\n","_ _ _\n","_ _ _\n","Action: 4\n","\n","Player making move O\n","O _ _\n","_ X _\n","_ _ _\n","Action: 1\n","\n","Player making move X\n","O O _\n","_ X _\n","_ _ _\n","Action: 2\n","\n","Player making move O\n","O O X\n","_ X _\n","_ _ _\n","Action: 6\n","\n","Player making move X\n","O O X\n","_ X _\n","O _ _\n","Action: 3\n","\n","Player making move O\n","O O X\n","X X _\n","O _ _\n","Action: 5\n","\n","Player making move X\n","O O X\n","X X O\n","O _ _\n","Action: 7\n","\n","Player making move O\n","O O X\n","X X O\n","O X _\n","Action: 8\n","\n","Player making move X\n","O O X\n","X X O\n","O X O\n","Reached terminal state? True\n","Utility for the 1st player 0\n","Utility for the 2nd player 0\n","Draw\n","Wall time: 75.6 ms\n"]}],"source":["%time judge(TicTacToe(), alphabeta, alphabeta)"]},{"cell_type":"markdown","metadata":{},"source":["## Migration"]},{"cell_type":"markdown","metadata":{},"source":["The following cell defines the rules for the game Migration. See https://www.di.fc.ul.pt/~jpn/gv/migration.htm for a complete description of rules. This implementation is somewhat more flexible: instead of using a board of fixed size, the size of a board is defined by the constructor parameter `n`. The first player that cannot move loses."]},{"cell_type":"code","execution_count":129,"metadata":{},"outputs":[],"source":["import math\n","\n","class Migration:\n","    def __init__(self, n):\n","        self.n = n\n","    \n","    @property\n","    def initial_state(self):\n","        board = [[0]*self.n for _ in range(self.n)]\n","        k = math.ceil(self.n/2 - 1)\n","        for y in range(k):\n","            for x in range(y + 1, self.n - y - 1):\n","                board[x][y] = 1    \n","        for x in range(k):\n","            for y in range(x + 1, self.n - x - 1):\n","                board[self.n - x - 1][y] = 2\n","        board = tuple((tuple(row) for row in board))\n","        return (1, board)\n","    \n","    def player(self, state):\n","        return state[0]\n","    \n","    def _is_valid(self, x, y):\n","        return 0 <= x < self.n and 0 <= y < self.n\n","    \n","    def actions(self, state):\n","        board = state[1]\n","        player = self.player(state)\n","        opp = opponent(player)\n","        if player == 1:\n","            dx, dy = 0, 1\n","        else:\n","            assert player == 2\n","            dx, dy = -1, 0\n","        actions = []\n","        for x in range(self.n):\n","            nx = x + dx\n","            for y in range(self.n):\n","                ny = y + dy\n","                if board[x][y] == player and self._is_valid(nx, ny) and board[nx][ny] == 0:\n","                    actions.append((x, y, nx, ny))\n","        return actions\n","    \n","    def result(self, state, action):\n","        x, y, nx, ny = action\n","        player, board = state\n","        board = [list(row) for row in board]\n","        assert board[x][y] == player\n","        assert board[nx][ny] == 0\n","        board[x][y] = 0\n","        board[nx][ny] = player\n","        board = tuple((tuple(row) for row in board))\n","        return (opponent(player), board)\n","    \n","    def is_terminal(self, state):\n","        return len(self.actions(state)) == 0\n","        \n","    def utility(self, state, player):\n","        assert self.is_terminal(state)\n","        if self.player(state) == player:\n","            return -1\n","        else:\n","            return 1\n","        \n","    def print_state(self, state):\n","        print(\"Player making move\", \"_\\u25CB\\u25CF\"[state[0]])\n","        for row in state[1]:\n","            print(*[\"_\\u25CB\\u25CF\"[v] for v in row])"]},{"cell_type":"markdown","metadata":{},"source":["Let's first see the initial state."]},{"cell_type":"code","execution_count":130,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ○\n","_ _ _ _ _ _ _ _\n","○ _ _ _ _ _ _ _\n","○ ○ _ _ _ _ _ _\n","○ ○ ○ _ _ _ _ _\n","○ ○ ○ _ _ _ _ _\n","○ ○ _ ● ● _ _ _\n","○ _ ● ● ● ● _ _\n","_ ● ● ● ● ● ● _\n"]}],"source":["game = Migration(8)\n","state = game.initial_state\n","game.print_state(state)"]},{"cell_type":"markdown","metadata":{},"source":["Now, white makes a move."]},{"cell_type":"code","execution_count":131,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ●\n","_ _ _ _ _ _ _ _\n","_ ○ _ _ _ _ _ _\n","○ ○ _ _ _ _ _ _\n","○ ○ ○ _ _ _ _ _\n","○ ○ ○ _ _ _ _ _\n","○ ○ _ ● ● _ _ _\n","○ _ ● ● ● ● _ _\n","_ ● ● ● ● ● ● _\n"]}],"source":["move = game.actions(state)[0]\n","state = game.result(state, move)\n","game.print_state(state)"]},{"cell_type":"markdown","metadata":{},"source":["As this is a turn-taking game, now it is time for black."]},{"cell_type":"code","execution_count":132,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ○\n","_ _ _ _ _ _ _ _\n","_ ○ _ _ _ _ _ _\n","○ ○ _ _ _ _ _ _\n","○ ○ ○ _ _ _ _ _\n","○ ○ ○ ● _ _ _ _\n","○ ○ _ _ ● _ _ _\n","○ _ ● ● ● ● _ _\n","_ ● ● ● ● ● ● _\n"]}],"source":["move = game.actions(state)[0]\n","state = game.result(state, move)\n","game.print_state(state)"]},{"cell_type":"markdown","metadata":{},"source":["Let's see how well alpha-beta fares on a $4 \\times 4$ board. The following cell should terminate within a few seconds."]},{"cell_type":"code","execution_count":133,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ○\n","_ _ _ _\n","○ _ _ _\n","○ _ _ _\n","_ ● ● _\n","Action: (1, 0, 1, 1)\n","\n","Player making move ●\n","_ _ _ _\n","_ ○ _ _\n","○ _ _ _\n","_ ● ● _\n","Action: (3, 1, 2, 1)\n","\n","Player making move ○\n","_ _ _ _\n","_ ○ _ _\n","○ ● _ _\n","_ _ ● _\n","Action: (1, 1, 1, 2)\n","\n","Player making move ●\n","_ _ _ _\n","_ _ ○ _\n","○ ● _ _\n","_ _ ● _\n","Action: (2, 1, 1, 1)\n","\n","Player making move ○\n","_ _ _ _\n","_ ● ○ _\n","○ _ _ _\n","_ _ ● _\n","Action: (1, 2, 1, 3)\n","\n","Player making move ●\n","_ _ _ _\n","_ ● _ ○\n","○ _ _ _\n","_ _ ● _\n","Action: (1, 1, 0, 1)\n","\n","Player making move ○\n","_ ● _ _\n","_ _ _ ○\n","○ _ _ _\n","_ _ ● _\n","Action: (2, 0, 2, 1)\n","\n","Player making move ●\n","_ ● _ _\n","_ _ _ ○\n","_ ○ _ _\n","_ _ ● _\n","Action: (3, 2, 2, 2)\n","\n","Player making move ○\n","_ ● _ _\n","_ _ _ ○\n","_ ○ ● _\n","_ _ _ _\n","Reached terminal state? True\n","Utility for the 1st player -1\n","Utility for the 2nd player 1\n","Winner: 2nd player\n"]}],"source":["judge(Migration(4), alphabeta, alphabeta)"]},{"cell_type":"markdown","metadata":{},"source":["A $5 \\times 5$ board is somewhat more challenging, but should still be within reach. The following cell should terminate within, say, 30 seconds at most."]},{"cell_type":"code","execution_count":134,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ○\n","_ _ _ _ _\n","○ _ _ _ _\n","○ ○ _ _ _\n","○ _ ● _ _\n","_ ● ● ● _\n","Action: (2, 1, 2, 2)\n","\n","Player making move ●\n","_ _ _ _ _\n","○ _ _ _ _\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ ● ● ● _\n","Action: (4, 1, 3, 1)\n","\n","Player making move ○\n","_ _ _ _ _\n","○ _ _ _ _\n","○ _ ○ _ _\n","○ ● ● _ _\n","_ _ ● ● _\n","Action: (1, 0, 1, 1)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ ○ _ _ _\n","○ _ ○ _ _\n","○ ● ● _ _\n","_ _ ● ● _\n","Action: (3, 1, 2, 1)\n","\n","Player making move ○\n","_ _ _ _ _\n","_ ○ _ _ _\n","○ ● ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (1, 1, 1, 2)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ _ ○ _ _\n","○ ● ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (2, 1, 1, 1)\n","\n","Player making move ○\n","_ _ _ _ _\n","_ ● ○ _ _\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (1, 2, 1, 3)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ ● _ ○ _\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (1, 1, 0, 1)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ ○ _\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (1, 3, 1, 4)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ _ ○\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (4, 3, 3, 3)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ _ ○\n","○ _ ○ _ _\n","○ _ ● ● _\n","_ _ ● _ _\n","Action: (2, 0, 2, 1)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ _ ○\n","_ ○ ○ _ _\n","○ _ ● ● _\n","_ _ ● _ _\n","Action: (3, 3, 2, 3)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ _ ○\n","_ ○ ○ ● _\n","○ _ ● _ _\n","_ _ ● _ _\n","Action: (3, 0, 3, 1)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ _ ○\n","_ ○ ○ ● _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (2, 3, 1, 3)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ ● ○\n","_ ○ ○ _ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (2, 2, 2, 3)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ ● ○\n","_ ○ _ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (1, 3, 0, 3)\n","\n","Player making move ○\n","_ ● _ ● _\n","_ _ _ _ ○\n","_ ○ _ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (2, 1, 2, 2)\n","\n","Player making move ●\n","_ ● _ ● _\n","_ _ _ _ ○\n","_ _ ○ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Reached terminal state? True\n","Utility for the 1st player 1\n","Utility for the 2nd player -1\n","Winner: 1st player\n","Wall time: 5.32 s\n"]}],"source":["%time judge(Migration(5), alphabeta, alphabeta)"]},{"cell_type":"markdown","metadata":{},"source":["It goes without saying that alpha-beta should beat the dummy. Each of the following two cells should terminate within 30 seconds, and alpha-beta should be the winner."]},{"cell_type":"code","execution_count":135,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ○\n","_ _ _ _ _\n","○ _ _ _ _\n","○ ○ _ _ _\n","○ _ ● _ _\n","_ ● ● ● _\n","Action: (2, 1, 2, 2)\n","\n","Player making move ●\n","_ _ _ _ _\n","○ _ _ _ _\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ ● ● ● _\n","Action: (4, 1, 3, 1)\n","\n","Player making move ○\n","_ _ _ _ _\n","○ _ _ _ _\n","○ _ ○ _ _\n","○ ● ● _ _\n","_ _ ● ● _\n","Action: (1, 0, 1, 1)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ ○ _ _ _\n","○ _ ○ _ _\n","○ ● ● _ _\n","_ _ ● ● _\n","Action: (3, 1, 2, 1)\n","\n","Player making move ○\n","_ _ _ _ _\n","_ ○ _ _ _\n","○ ● ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (1, 1, 1, 2)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ _ ○ _ _\n","○ ● ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (2, 1, 1, 1)\n","\n","Player making move ○\n","_ _ _ _ _\n","_ ● ○ _ _\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (1, 2, 1, 3)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ ● _ ○ _\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (1, 1, 0, 1)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ ○ _\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (1, 3, 1, 4)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ _ ○\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (4, 3, 3, 3)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ _ ○\n","○ _ ○ _ _\n","○ _ ● ● _\n","_ _ ● _ _\n","Action: (2, 0, 2, 1)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ _ ○\n","_ ○ ○ _ _\n","○ _ ● ● _\n","_ _ ● _ _\n","Action: (3, 3, 2, 3)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ _ ○\n","_ ○ ○ ● _\n","○ _ ● _ _\n","_ _ ● _ _\n","Action: (3, 0, 3, 1)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ _ ○\n","_ ○ ○ ● _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (2, 3, 1, 3)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ ● ○\n","_ ○ ○ _ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (2, 2, 2, 3)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ ● ○\n","_ ○ _ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (1, 3, 0, 3)\n","\n","Player making move ○\n","_ ● _ ● _\n","_ _ _ _ ○\n","_ ○ _ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (2, 1, 2, 2)\n","\n","Player making move ●\n","_ ● _ ● _\n","_ _ _ _ ○\n","_ _ ○ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Reached terminal state? True\n","Utility for the 1st player 1\n","Utility for the 2nd player -1\n","Winner: 1st player\n","Wall time: 4.12 s\n"]}],"source":["%time judge(Migration(5), alphabeta, dummy)"]},{"cell_type":"code","execution_count":136,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ○\n","_ _ _ _ _\n","○ _ _ _ _\n","○ ○ _ _ _\n","○ _ ● _ _\n","_ ● ● ● _\n","Action: (1, 0, 1, 1)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ ○ _ _ _\n","○ ○ _ _ _\n","○ _ ● _ _\n","_ ● ● ● _\n","Action: (3, 2, 2, 2)\n","\n","Player making move ○\n","_ _ _ _ _\n","_ ○ _ _ _\n","○ ○ ● _ _\n","○ _ _ _ _\n","_ ● ● ● _\n","Action: (1, 1, 1, 2)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ _ ○ _ _\n","○ ○ ● _ _\n","○ _ _ _ _\n","_ ● ● ● _\n","Action: (4, 1, 3, 1)\n","\n","Player making move ○\n","_ _ _ _ _\n","_ _ ○ _ _\n","○ ○ ● _ _\n","○ ● _ _ _\n","_ _ ● ● _\n","Action: (1, 2, 1, 3)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ _ _ ○ _\n","○ ○ ● _ _\n","○ ● _ _ _\n","_ _ ● ● _\n","Action: (2, 2, 1, 2)\n","\n","Player making move ○\n","_ _ _ _ _\n","_ _ ● ○ _\n","○ ○ _ _ _\n","○ ● _ _ _\n","_ _ ● ● _\n","Action: (1, 3, 1, 4)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ _ ● _ ○\n","○ ○ _ _ _\n","○ ● _ _ _\n","_ _ ● ● _\n","Action: (1, 2, 0, 2)\n","\n","Player making move ○\n","_ _ ● _ _\n","_ _ _ _ ○\n","○ ○ _ _ _\n","○ ● _ _ _\n","_ _ ● ● _\n","Action: (2, 1, 2, 2)\n","\n","Player making move ●\n","_ _ ● _ _\n","_ _ _ _ ○\n","○ _ ○ _ _\n","○ ● _ _ _\n","_ _ ● ● _\n","Action: (3, 1, 2, 1)\n","\n","Player making move ○\n","_ _ ● _ _\n","_ _ _ _ ○\n","○ ● ○ _ _\n","○ _ _ _ _\n","_ _ ● ● _\n","Action: (2, 2, 2, 3)\n","\n","Player making move ●\n","_ _ ● _ _\n","_ _ _ _ ○\n","○ ● _ ○ _\n","○ _ _ _ _\n","_ _ ● ● _\n","Action: (2, 1, 1, 1)\n","\n","Player making move ○\n","_ _ ● _ _\n","_ ● _ _ ○\n","○ _ _ ○ _\n","○ _ _ _ _\n","_ _ ● ● _\n","Action: (2, 0, 2, 1)\n","\n","Player making move ●\n","_ _ ● _ _\n","_ ● _ _ ○\n","_ ○ _ ○ _\n","○ _ _ _ _\n","_ _ ● ● _\n","Action: (1, 1, 0, 1)\n","\n","Player making move ○\n","_ ● ● _ _\n","_ _ _ _ ○\n","_ ○ _ ○ _\n","○ _ _ _ _\n","_ _ ● ● _\n","Action: (2, 1, 2, 2)\n","\n","Player making move ●\n","_ ● ● _ _\n","_ _ _ _ ○\n","_ _ ○ ○ _\n","○ _ _ _ _\n","_ _ ● ● _\n","Action: (4, 3, 3, 3)\n","\n","Player making move ○\n","_ ● ● _ _\n","_ _ _ _ ○\n","_ _ ○ ○ _\n","○ _ _ ● _\n","_ _ ● _ _\n","Action: (2, 3, 2, 4)\n","\n","Player making move ●\n","_ ● ● _ _\n","_ _ _ _ ○\n","_ _ ○ _ ○\n","○ _ _ ● _\n","_ _ ● _ _\n","Action: (3, 3, 2, 3)\n","\n","Player making move ○\n","_ ● ● _ _\n","_ _ _ _ ○\n","_ _ ○ ● ○\n","○ _ _ _ _\n","_ _ ● _ _\n","Action: (3, 0, 3, 1)\n","\n","Player making move ●\n","_ ● ● _ _\n","_ _ _ _ ○\n","_ _ ○ ● ○\n","_ ○ _ _ _\n","_ _ ● _ _\n","Action: (4, 2, 3, 2)\n","\n","Player making move ○\n","_ ● ● _ _\n","_ _ _ _ ○\n","_ _ ○ ● ○\n","_ ○ ● _ _\n","_ _ _ _ _\n","Reached terminal state? True\n","Utility for the 1st player -1\n","Utility for the 2nd player 1\n","Winner: 2nd player\n","Wall time: 2.15 s\n"]}],"source":["%time judge(Migration(5), dummy, alphabeta)"]},{"cell_type":"markdown","metadata":{},"source":["## Task 3: Alpha-beta with limited depth and heuristic evaluation"]},{"cell_type":"markdown","metadata":{},"source":["Alpha-beta is a complete and optimal algorithm, but still too slow.\n","In practice it is used as a heuristic algorithm: sometimes searching is terminated before reaching a terminal node and some heuristic evaluation of the reached non-terminal state is returned instead of the utility of a terminal state.\n","How to evaluate non-terminal states and how to decide when to terminate search is an extremely rich topic.\n","\n","Complete the cells below:\n","\n","* Implement the function `evaluate` in `MigrationWithHeuristic` such that it returns some evaluation of the given `state` from the point of view of the given `player`. The more promising the state for the player, the higher value should be returned.\n","* Implement the function `__call__` in `HeuristicAlphaBeta` such that it is an implementation of the alpha-beta algorithm, but should the recursion depth reach `self.max_depth` the heuristic evaluation should be returned instead of descending further in the game tree.\n","\n","Minimax and alpha-beta are game-agnostic and thus for them states are opaque. On the other hand `evaluate` is not game-agnostic, but it is also not (strictly speaking) a part of the rules of a game. Still, it needs to access the internals of the state and in the provided implementation of `Migration` the state is a 2-tuple:\n","\n","1. The id of a player to make a move\n","2. The representation of a board as a tuple of tuples, forming an `self.n` $\\times$ `self.n` array. Each element of this tuple of tuples is either:\n","   * 0 - an empty cell\n","   * 1 - a stone of player 1\n","   * 2 - a stone of player 2"]},{"cell_type":"code","execution_count":137,"metadata":{},"outputs":[],"source":["class MigrationWithHeuristic(Migration):\n","    #(⬇️) evaluete returns difference of numbers of moves that both players can do, divided by total number of stones they have in order to normalize\n","    # result in range [-1,1], so it will never give more or less then utility in final state\n","    def evaluate(self, state, player):\n","        return (len(self.actions((player, state[1]))) - len(self.actions((opponent(player), state[1]))))/(sum(range(int(self.n/2)))+sum(range(math.ceil(self.n/2))))"]},{"cell_type":"code","execution_count":138,"metadata":{},"outputs":[],"source":["#(⬇️) same as alpha-beta, only using max depth and evaluation method when it reches it\n","class HeuristicAlphaBeta:\n","    def __init__(self, max_depth):\n","        self.max_depth = max_depth\n","\n","    def max_heuristics(self, game: Game, state, player, A, B, depth):\n","        depth += 1\n","        if game.is_terminal(state):\n","            return game.utility(state,player), None\n","        if depth > self.max_depth:\n","            return game.evaluate(state,player), None\n","        v = float('-inf')\n","        for a in game.actions(state):\n","            v2, a2 = self.min_heuristics(game, game.result(state,a), player, A, B, depth)\n","            if v2 > v:\n","                v, move = v2, a\n","                A = max(A,v)\n","            if v >= B:\n","                return v, move\n","        return v, move\n","        \n","\n","    def min_heuristics(self, game: Game, state, player, A, B, depth):\n","        depth += 1\n","        if game.is_terminal(state):\n","            return game.utility(state,player), None\n","        if depth > self.max_depth:\n","            return game.evaluate(state,player), None\n","        v = float('inf')\n","        for a in game.actions(state):\n","            v2, a2 = self.max_heuristics(game, game.result(state,a), player, A, B, depth)\n","            if v2 < v:\n","                v, move = v2, a\n","                B  = min(B,v)\n","            if v <= A:\n","                return v, move\n","        return v, move\n","        \n","\n","    def __call__(self, game, state):\n","        player = game.player(state)\n","        value, move = self.max_heuristics(game, state, player, float('-inf'), float('inf'), 0)\n","        return move"]},{"cell_type":"markdown","metadata":{},"source":["## Task 4: Comparing alpha-beta and alpha-beta with heuristics"]},{"cell_type":"markdown","metadata":{},"source":["As you have seen $5\\times 5$ board in this game is easy enough for alpha-beta, so we can use it to compare complete alpha-beta and alpha-beta with heuristics. Copy the next two cell a few times, and consider different depths for `HeuristicAlphaBeta`. Keep in mind that the game may be slightly unfair and thus you should always allow every player play in both positions before making conclusions. Afterwards, answer the question below the code cells."]},{"cell_type":"code","execution_count":139,"metadata":{"scrolled":true,"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ○\n","_ _ _ _ _\n","○ _ _ _ _\n","○ ○ _ _ _\n","○ _ ● _ _\n","_ ● ● ● _\n","Action: (2, 1, 2, 2)\n","\n","Player making move ●\n","_ _ _ _ _\n","○ _ _ _ _\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ ● ● ● _\n","Action: (4, 1, 3, 1)\n","\n","Player making move ○\n","_ _ _ _ _\n","○ _ _ _ _\n","○ _ ○ _ _\n","○ ● ● _ _\n","_ _ ● ● _\n","Action: (2, 0, 2, 1)\n","\n","Player making move ●\n","_ _ _ _ _\n","○ _ _ _ _\n","_ ○ ○ _ _\n","○ ● ● _ _\n","_ _ ● ● _\n","Action: (4, 3, 3, 3)\n","\n","Player making move ○\n","_ _ _ _ _\n","○ _ _ _ _\n","_ ○ ○ _ _\n","○ ● ● ● _\n","_ _ ● _ _\n","Action: (1, 0, 1, 1)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ ○ _ _ _\n","_ ○ ○ _ _\n","○ ● ● ● _\n","_ _ ● _ _\n","Action: (3, 3, 2, 3)\n","\n","Player making move ○\n","_ _ _ _ _\n","_ ○ _ _ _\n","_ ○ ○ ● _\n","○ ● ● _ _\n","_ _ ● _ _\n","Action: (1, 1, 1, 2)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ _ ○ _ _\n","_ ○ ○ ● _\n","○ ● ● _ _\n","_ _ ● _ _\n","Action: (2, 3, 1, 3)\n","\n","Player making move ○\n","_ _ _ _ _\n","_ _ ○ ● _\n","_ ○ ○ _ _\n","○ ● ● _ _\n","_ _ ● _ _\n","Action: (2, 2, 2, 3)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ _ ○ ● _\n","_ ○ _ ○ _\n","○ ● ● _ _\n","_ _ ● _ _\n","Action: (3, 2, 2, 2)\n","\n","Player making move ○\n","_ _ _ _ _\n","_ _ ○ ● _\n","_ ○ ● ○ _\n","○ ● _ _ _\n","_ _ ● _ _\n","Action: (2, 3, 2, 4)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ _ ○ ● _\n","_ ○ ● _ ○\n","○ ● _ _ _\n","_ _ ● _ _\n","Action: (1, 3, 0, 3)\n","\n","Player making move ○\n","_ _ _ ● _\n","_ _ ○ _ _\n","_ ○ ● _ ○\n","○ ● _ _ _\n","_ _ ● _ _\n","Action: (1, 2, 1, 3)\n","\n","Player making move ●\n","_ _ _ ● _\n","_ _ _ ○ _\n","_ ○ ● _ ○\n","○ ● _ _ _\n","_ _ ● _ _\n","Action: (2, 2, 1, 2)\n","\n","Player making move ○\n","_ _ _ ● _\n","_ _ ● ○ _\n","_ ○ _ _ ○\n","○ ● _ _ _\n","_ _ ● _ _\n","Action: (1, 3, 1, 4)\n","\n","Player making move ●\n","_ _ _ ● _\n","_ _ ● _ ○\n","_ ○ _ _ ○\n","○ ● _ _ _\n","_ _ ● _ _\n","Action: (1, 2, 0, 2)\n","\n","Player making move ○\n","_ _ ● ● _\n","_ _ _ _ ○\n","_ ○ _ _ ○\n","○ ● _ _ _\n","_ _ ● _ _\n","Action: (2, 1, 2, 2)\n","\n","Player making move ●\n","_ _ ● ● _\n","_ _ _ _ ○\n","_ _ ○ _ ○\n","○ ● _ _ _\n","_ _ ● _ _\n","Action: (3, 1, 2, 1)\n","\n","Player making move ○\n","_ _ ● ● _\n","_ _ _ _ ○\n","_ ● ○ _ ○\n","○ _ _ _ _\n","_ _ ● _ _\n","Action: (2, 2, 2, 3)\n","\n","Player making move ●\n","_ _ ● ● _\n","_ _ _ _ ○\n","_ ● _ ○ ○\n","○ _ _ _ _\n","_ _ ● _ _\n","Action: (2, 1, 1, 1)\n","\n","Player making move ○\n","_ _ ● ● _\n","_ ● _ _ ○\n","_ _ _ ○ ○\n","○ _ _ _ _\n","_ _ ● _ _\n","Action: (3, 0, 3, 1)\n","\n","Player making move ●\n","_ _ ● ● _\n","_ ● _ _ ○\n","_ _ _ ○ ○\n","_ ○ _ _ _\n","_ _ ● _ _\n","Action: (4, 2, 3, 2)\n","\n","Player making move ○\n","_ _ ● ● _\n","_ ● _ _ ○\n","_ _ _ ○ ○\n","_ ○ ● _ _\n","_ _ _ _ _\n","Reached terminal state? True\n","Utility for the 1st player -1\n","Utility for the 2nd player 1\n","Winner: 2nd player\n","Wall time: 765 ms\n"]}],"source":["#(⬇️) depth too low for heuristics to win even tho it starts in winning state\n","%time judge(MigrationWithHeuristic(5), HeuristicAlphaBeta(3), alphabeta)"]},{"cell_type":"code","execution_count":140,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ○\n","_ _ _ _ _\n","○ _ _ _ _\n","○ ○ _ _ _\n","○ _ ● _ _\n","_ ● ● ● _\n","Action: (2, 1, 2, 2)\n","\n","Player making move ●\n","_ _ _ _ _\n","○ _ _ _ _\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ ● ● ● _\n","Action: (4, 1, 3, 1)\n","\n","Player making move ○\n","_ _ _ _ _\n","○ _ _ _ _\n","○ _ ○ _ _\n","○ ● ● _ _\n","_ _ ● ● _\n","Action: (1, 0, 1, 1)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ ○ _ _ _\n","○ _ ○ _ _\n","○ ● ● _ _\n","_ _ ● ● _\n","Action: (3, 1, 2, 1)\n","\n","Player making move ○\n","_ _ _ _ _\n","_ ○ _ _ _\n","○ ● ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (1, 1, 1, 2)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ _ ○ _ _\n","○ ● ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (2, 1, 1, 1)\n","\n","Player making move ○\n","_ _ _ _ _\n","_ ● ○ _ _\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (3, 0, 3, 1)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ ● ○ _ _\n","○ _ ○ _ _\n","_ ○ ● _ _\n","_ _ ● ● _\n","Action: (1, 1, 0, 1)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ ○ _ _\n","○ _ ○ _ _\n","_ ○ ● _ _\n","_ _ ● ● _\n","Action: (1, 2, 1, 3)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ ○ _\n","○ _ ○ _ _\n","_ ○ ● _ _\n","_ _ ● ● _\n","Action: (4, 3, 3, 3)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ ○ _\n","○ _ ○ _ _\n","_ ○ ● ● _\n","_ _ ● _ _\n","Action: (2, 2, 2, 3)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ ○ _\n","○ _ _ ○ _\n","_ ○ ● ● _\n","_ _ ● _ _\n","Action: (3, 2, 2, 2)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ ○ _\n","○ _ ● ○ _\n","_ ○ _ ● _\n","_ _ ● _ _\n","Action: (3, 1, 3, 2)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ ○ _\n","○ _ ● ○ _\n","_ _ ○ ● _\n","_ _ ● _ _\n","Action: (2, 2, 1, 2)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ ● ○ _\n","○ _ _ ○ _\n","_ _ ○ ● _\n","_ _ ● _ _\n","Action: (1, 3, 1, 4)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ ● _ ○\n","○ _ _ ○ _\n","_ _ ○ ● _\n","_ _ ● _ _\n","Action: (1, 2, 0, 2)\n","\n","Player making move ○\n","_ ● ● _ _\n","_ _ _ _ ○\n","○ _ _ ○ _\n","_ _ ○ ● _\n","_ _ ● _ _\n","Action: (2, 0, 2, 1)\n","\n","Player making move ●\n","_ ● ● _ _\n","_ _ _ _ ○\n","_ ○ _ ○ _\n","_ _ ○ ● _\n","_ _ ● _ _\n","Reached terminal state? True\n","Utility for the 1st player 1\n","Utility for the 2nd player -1\n","Winner: 1st player\n","Wall time: 1.28 s\n"]}],"source":["#(⬇️) lowest depth, in which heuristics beats alpha-beta, when it starts in winning state \n","%time judge(MigrationWithHeuristic(5), HeuristicAlphaBeta(4), alphabeta)"]},{"cell_type":"code","execution_count":153,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ○\n","_ _ _ _ _\n","○ _ _ _ _\n","○ ○ _ _ _\n","○ _ ● _ _\n","_ ● ● ● _\n","Action: (2, 1, 2, 2)\n","\n","Player making move ●\n","_ _ _ _ _\n","○ _ _ _ _\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ ● ● ● _\n","Action: (4, 1, 3, 1)\n","\n","Player making move ○\n","_ _ _ _ _\n","○ _ _ _ _\n","○ _ ○ _ _\n","○ ● ● _ _\n","_ _ ● ● _\n","Action: (1, 0, 1, 1)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ ○ _ _ _\n","○ _ ○ _ _\n","○ ● ● _ _\n","_ _ ● ● _\n","Action: (3, 1, 2, 1)\n","\n","Player making move ○\n","_ _ _ _ _\n","_ ○ _ _ _\n","○ ● ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (1, 1, 1, 2)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ _ ○ _ _\n","○ ● ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (2, 1, 1, 1)\n","\n","Player making move ○\n","_ _ _ _ _\n","_ ● ○ _ _\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (1, 2, 1, 3)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ ● _ ○ _\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (1, 1, 0, 1)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ ○ _\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (1, 3, 1, 4)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ _ ○\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (4, 3, 3, 3)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ _ ○\n","○ _ ○ _ _\n","○ _ ● ● _\n","_ _ ● _ _\n","Action: (2, 0, 2, 1)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ _ ○\n","_ ○ ○ _ _\n","○ _ ● ● _\n","_ _ ● _ _\n","Action: (3, 3, 2, 3)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ _ ○\n","_ ○ ○ ● _\n","○ _ ● _ _\n","_ _ ● _ _\n","Action: (3, 0, 3, 1)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ _ ○\n","_ ○ ○ ● _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (2, 3, 1, 3)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ ● ○\n","_ ○ ○ _ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (2, 2, 2, 3)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ ● ○\n","_ ○ _ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (1, 3, 0, 3)\n","\n","Player making move ○\n","_ ● _ ● _\n","_ _ _ _ ○\n","_ ○ _ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (2, 1, 2, 2)\n","\n","Player making move ●\n","_ ● _ ● _\n","_ _ _ _ ○\n","_ _ ○ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Reached terminal state? True\n","Utility for the 1st player 1\n","Utility for the 2nd player -1\n","Winner: 1st player\n","Wall time: 4.95 s\n"]}],"source":["#(⬇️) very big depth, turning heuristics into normal alpha-beta \n","%time judge(MigrationWithHeuristic(5), HeuristicAlphaBeta(1000), alphabeta)"]},{"cell_type":"code","execution_count":142,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ○\n","_ _ _ _ _\n","○ _ _ _ _\n","○ ○ _ _ _\n","○ _ ● _ _\n","_ ● ● ● _\n","Action: (2, 1, 2, 2)\n","\n","Player making move ●\n","_ _ _ _ _\n","○ _ _ _ _\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ ● ● ● _\n","Action: (4, 1, 3, 1)\n","\n","Player making move ○\n","_ _ _ _ _\n","○ _ _ _ _\n","○ _ ○ _ _\n","○ ● ● _ _\n","_ _ ● ● _\n","Action: (1, 0, 1, 1)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ ○ _ _ _\n","○ _ ○ _ _\n","○ ● ● _ _\n","_ _ ● ● _\n","Action: (3, 1, 2, 1)\n","\n","Player making move ○\n","_ _ _ _ _\n","_ ○ _ _ _\n","○ ● ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (1, 1, 1, 2)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ _ ○ _ _\n","○ ● ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (4, 3, 3, 3)\n","\n","Player making move ○\n","_ _ _ _ _\n","_ _ ○ _ _\n","○ ● ○ _ _\n","○ _ ● ● _\n","_ _ ● _ _\n","Action: (1, 2, 1, 3)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ _ _ ○ _\n","○ ● ○ _ _\n","○ _ ● ● _\n","_ _ ● _ _\n","Action: (2, 1, 1, 1)\n","\n","Player making move ○\n","_ _ _ _ _\n","_ ● _ ○ _\n","○ _ ○ _ _\n","○ _ ● ● _\n","_ _ ● _ _\n","Action: (1, 3, 1, 4)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ ● _ _ ○\n","○ _ ○ _ _\n","○ _ ● ● _\n","_ _ ● _ _\n","Action: (3, 3, 2, 3)\n","\n","Player making move ○\n","_ _ _ _ _\n","_ ● _ _ ○\n","○ _ ○ ● _\n","○ _ ● _ _\n","_ _ ● _ _\n","Action: (2, 0, 2, 1)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ ● _ _ ○\n","_ ○ ○ ● _\n","○ _ ● _ _\n","_ _ ● _ _\n","Action: (1, 1, 0, 1)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ _ ○\n","_ ○ ○ ● _\n","○ _ ● _ _\n","_ _ ● _ _\n","Action: (3, 0, 3, 1)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ _ ○\n","_ ○ ○ ● _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (2, 3, 1, 3)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ ● ○\n","_ ○ ○ _ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (2, 2, 2, 3)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ ● ○\n","_ ○ _ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (3, 2, 2, 2)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ ● ○\n","_ ○ ● ○ _\n","_ ○ _ _ _\n","_ _ ● _ _\n","Action: (3, 1, 3, 2)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ ● ○\n","_ ○ ● ○ _\n","_ _ ○ _ _\n","_ _ ● _ _\n","Action: (1, 3, 0, 3)\n","\n","Player making move ○\n","_ ● _ ● _\n","_ _ _ _ ○\n","_ ○ ● ○ _\n","_ _ ○ _ _\n","_ _ ● _ _\n","Action: (2, 3, 2, 4)\n","\n","Player making move ●\n","_ ● _ ● _\n","_ _ _ _ ○\n","_ ○ ● _ ○\n","_ _ ○ _ _\n","_ _ ● _ _\n","Action: (2, 2, 1, 2)\n","\n","Player making move ○\n","_ ● _ ● _\n","_ _ ● _ ○\n","_ ○ _ _ ○\n","_ _ ○ _ _\n","_ _ ● _ _\n","Action: (2, 1, 2, 2)\n","\n","Player making move ●\n","_ ● _ ● _\n","_ _ ● _ ○\n","_ _ ○ _ ○\n","_ _ ○ _ _\n","_ _ ● _ _\n","Action: (1, 2, 0, 2)\n","\n","Player making move ○\n","_ ● ● ● _\n","_ _ _ _ ○\n","_ _ ○ _ ○\n","_ _ ○ _ _\n","_ _ ● _ _\n","Action: (2, 2, 2, 3)\n","\n","Player making move ●\n","_ ● ● ● _\n","_ _ _ _ ○\n","_ _ _ ○ ○\n","_ _ ○ _ _\n","_ _ ● _ _\n","Reached terminal state? True\n","Utility for the 1st player 1\n","Utility for the 2nd player -1\n","Winner: 1st player\n","Wall time: 4.13 s\n"]}],"source":["#(⬇️) alpha-beta never loses to heuristics, when it starts in winnning state\n","%time judge(MigrationWithHeuristic(5), alphabeta, HeuristicAlphaBeta(5))"]},{"cell_type":"code","execution_count":156,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ○\n","_ _ _ _ _\n","○ _ _ _ _\n","○ ○ _ _ _\n","○ _ ● _ _\n","_ ● ● ● _\n","Action: (2, 1, 2, 2)\n","\n","Player making move ●\n","_ _ _ _ _\n","○ _ _ _ _\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ ● ● ● _\n","Action: (4, 1, 3, 1)\n","\n","Player making move ○\n","_ _ _ _ _\n","○ _ _ _ _\n","○ _ ○ _ _\n","○ ● ● _ _\n","_ _ ● ● _\n","Action: (1, 0, 1, 1)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ ○ _ _ _\n","○ _ ○ _ _\n","○ ● ● _ _\n","_ _ ● ● _\n","Action: (3, 1, 2, 1)\n","\n","Player making move ○\n","_ _ _ _ _\n","_ ○ _ _ _\n","○ ● ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (1, 1, 1, 2)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ _ ○ _ _\n","○ ● ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (2, 1, 1, 1)\n","\n","Player making move ○\n","_ _ _ _ _\n","_ ● ○ _ _\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (1, 2, 1, 3)\n","\n","Player making move ●\n","_ _ _ _ _\n","_ ● _ ○ _\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (1, 1, 0, 1)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ ○ _\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (1, 3, 1, 4)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ _ ○\n","○ _ ○ _ _\n","○ _ ● _ _\n","_ _ ● ● _\n","Action: (4, 3, 3, 3)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ _ ○\n","○ _ ○ _ _\n","○ _ ● ● _\n","_ _ ● _ _\n","Action: (2, 0, 2, 1)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ _ ○\n","_ ○ ○ _ _\n","○ _ ● ● _\n","_ _ ● _ _\n","Action: (3, 3, 2, 3)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ _ ○\n","_ ○ ○ ● _\n","○ _ ● _ _\n","_ _ ● _ _\n","Action: (3, 0, 3, 1)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ _ ○\n","_ ○ ○ ● _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (2, 3, 1, 3)\n","\n","Player making move ○\n","_ ● _ _ _\n","_ _ _ ● ○\n","_ ○ ○ _ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (2, 2, 2, 3)\n","\n","Player making move ●\n","_ ● _ _ _\n","_ _ _ ● ○\n","_ ○ _ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (1, 3, 0, 3)\n","\n","Player making move ○\n","_ ● _ ● _\n","_ _ _ _ ○\n","_ ○ _ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (2, 1, 2, 2)\n","\n","Player making move ●\n","_ ● _ ● _\n","_ _ _ _ ○\n","_ _ ○ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Reached terminal state? True\n","Utility for the 1st player 1\n","Utility for the 2nd player -1\n","Winner: 1st player\n","Wall time: 5.05 s\n"]}],"source":["#(⬇️) alpha-beta never loses to heuristics, when it starts in winnning state, even if we don't restrict max depth of heuristics\n","%time judge(MigrationWithHeuristic(5), alphabeta, HeuristicAlphaBeta(1000))"]},{"cell_type":"markdown","metadata":{},"source":["**Summarize your experiments briefly (what depths did you consider, how long did it took; if you've changed any other parameters from the defaults, specify the new values). Is complete alpha-beta always better than its heuristics variant, or do they become equally good at some point? Why do you think is that?**"]},{"cell_type":"markdown","metadata":{},"source":["All of cells didn't take too long to finish, but the shortest time was when heuristics variant could make first move and it had restricted depth, giving an answer quickly and reducing state to one that has lesser ammount of total moves for alpha-beta.\n","\n","heuritics variant can become as good in alpha-beta in some examples (when it starts in winning state) if evaluation function is done properly, and max depth is set to be big enough, but obviously it can never beat it when it doesn't have advantage from start."]},{"cell_type":"markdown","metadata":{},"source":["## Task 5: Comparing different depths of alpha-beta with heuristics"]},{"cell_type":"markdown","metadata":{},"source":["Now, let's switch to the original version of the game on the $8\\times 8$ board. Your heuristics alpha-beta should be capable of playing it against itself within a reasonable time limit (say, 30 seconds per game). Similarly to the previous task, copy the following cell multiple times and fiddle with the depths. Then, answer the question below the code cells."]},{"cell_type":"code","execution_count":161,"metadata":{},"outputs":[],"source":["#(⬇️) judge without printing\n","def judge2(game: Game, player1, player2):    \n","    state = game.initial_state\n","\n","    while not game.is_terminal(state):\n","        if game.player(state) == 1:\n","            action = player1(game, state)\n","        else:\n","            action = player2(game, state)\n","        state = game.result(state, action)\n","    u1 = game.utility(state, 1)\n","    u2 = game.utility(state, 2)\n","    if u1 > u2:\n","        return 1\n","    elif u1 < u2:\n","        return 2\n","    else:\n","        return '-'"]},{"cell_type":"code","execution_count":231,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   1: 2: 3: 4: 5: 6: 7:\n","1: 1  2  2  2  2  2  2 \n","2: 1  2  2  2  2  2  2 \n","3: 2  2  2  2  2  2  2 \n","4: 2  2  2  2  2  2  2 \n","5: 2  2  2  2  1  2  2 \n","6: 2  2  2  2  2  2  2 \n","7: 1  2  2  2  2  2  2 \n"]}],"source":["#(⬇️) visualisation that one friend inspired me to do\n","visualize = [(str(i)+':' if i != 0 else '  ' for i in range(8))]\n","n = 8\n","for i in range(1,n):\n","    temp = [str(i)+':']\n","    for j in range(1,n):\n","        temp.append(str(judge2(MigrationWithHeuristic(8), HeuristicAlphaBeta(i), HeuristicAlphaBeta(j)))+' ')\n","    visualize.append(temp)\n","for x in visualize:\n","    print(*x)"]},{"cell_type":"markdown","metadata":{},"source":["**Summarize your experiments briefly (what depths did you consider, how long did it took; if you've changed any other parameters from the defaults, specify the new values). Is the alpha-beta searching deeper always better than the shallower one? What about games when two alpha-betas of equal depth play against each other? Is there a clear pattern (e.g., the first/second player always wins), or does it change between different depths and/or differnt executions? Try to come up with an explanation for all the observations.**"]},{"cell_type":"markdown","metadata":{},"source":["First thing i noticed with these results is that for my heuristics and 8x8 board of Migration, second player is way more favorable to win then the first. First player could win only with: very little depths making both players do pretty random moves, depth of 7 to depth of 1 of second player and with depths of both players being 5. Last case came as a bit of a suprise, but the reason probably is that my heuristic evaluation might reward behaviour not always leading to optimal moves, at first it seemed certain that rewarding maximizing ammount of moves you can make, while minimizing moves your opponent can make should lead to decent moves, but now I'm not that sure of it. In this experiment shallow or deep max depth of search was less important than what starting state was like for each player, but as pointed earlier first player could win with second one when it had much deeper max depth."]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"vscode":{"interpreter":{"hash":"49970d8a70049253b09e428136da9c3839964945cfa4a73b1e61647b35cd54a8"}}},"nbformat":4,"nbformat_minor":4}
